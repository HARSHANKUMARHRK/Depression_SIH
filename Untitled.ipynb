{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079da62f-2015-46bd-ac53-a1dd2b8956d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 16:48:47.528261: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-16 16:48:47.528280: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a50584-d82c-44f1-9fd3-f086d9ee98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8660c357-f670-4880-84fe-106a7d5c846b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>-13.0</th>\n",
       "      <th>-109.0</th>\n",
       "      <th>-66.0</th>\n",
       "      <th>-9.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>-28.0</th>\n",
       "      <th>61.0</th>\n",
       "      <th>4.0.3</th>\n",
       "      <th>8.0.1</th>\n",
       "      <th>5.0.1</th>\n",
       "      <th>4.0.4</th>\n",
       "      <th>-7.0.1</th>\n",
       "      <th>-59.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2909 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      26.0  4.0  5.0   8.0  -1.0  -13.0  -109.0  -66.0  -9.0  2.0  ...  -28.0  \\\n",
       "0    -47.0 -6.0 -5.0  -7.0  13.0   -1.0    35.0  -10.0  10.0 -4.0  ...  -25.0   \n",
       "1    -19.0 -8.0 -8.0  -8.0 -21.0   -6.0   -79.0   12.0   0.0  5.0  ...  -83.0   \n",
       "2      2.0  3.0  0.0   2.0   0.0   22.0   106.0  -14.0 -16.0 -2.0  ...  -38.0   \n",
       "3      6.0  0.0  0.0  -2.0 -14.0   10.0   -51.0    5.0   7.0  0.0  ...   38.0   \n",
       "4     15.0 -5.0 -5.0 -15.0  12.0  -22.0   -38.0   36.0   9.0  6.0  ...  -26.0   \n",
       "...    ...  ...  ...   ...   ...    ...     ...    ...   ...  ...  ...    ...   \n",
       "2904 -12.0  0.0  0.0  -7.0  -4.0   -3.0    -1.0   -5.0   4.0 -1.0  ...   12.0   \n",
       "2905  -9.0 -1.0 -2.0   1.0 -13.0  -14.0   -59.0   -4.0  -9.0  0.0  ...   20.0   \n",
       "2906   3.0 -2.0 -2.0   4.0  18.0   -5.0   -31.0    7.0  -3.0 -3.0  ...   34.0   \n",
       "2907  -2.0 -2.0 -2.0   1.0  -3.0  -17.0   -33.0  -13.0   3.0  2.0  ...   -4.0   \n",
       "2908   0.0 -2.0 -3.0  -2.0   2.0    5.0    18.0   -1.0  -5.0 -2.0  ...   -2.0   \n",
       "\n",
       "      61.0  4.0.3  8.0.1  5.0.1  4.0.4  -7.0.1  -59.0  16.0  0  \n",
       "0     47.0    6.0    6.0    5.0   13.0    21.0  111.0  15.0  0  \n",
       "1      7.0    7.0    1.0   -8.0    7.0    21.0  114.0  48.0  0  \n",
       "2    -11.0    4.0    7.0   11.0   33.0    39.0  119.0  43.0  0  \n",
       "3    -35.0   -8.0    2.0    6.0  -13.0   -24.0 -112.0 -69.0  0  \n",
       "4      5.0    6.0    6.0   11.0    5.0    30.0  -48.0  25.0  0  \n",
       "...    ...    ...    ...    ...    ...     ...    ...   ... ..  \n",
       "2904  -3.0    0.0    2.0   -1.0   -1.0     4.0  -30.0 -20.0  0  \n",
       "2905  -4.0    0.0    0.0    0.0  -21.0   -10.0  -14.0 -29.0  0  \n",
       "2906  -7.0    4.0    4.0    2.0    1.0     4.0  -55.0  -4.0  0  \n",
       "2907   0.0    3.0    0.0    5.0    9.0     8.0  -13.0  11.0  0  \n",
       "2908  -4.0    6.0    1.0   -8.0  -15.0     3.0    5.0  10.0  0  \n",
       "\n",
       "[2909 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b9873e-e2c9-4ec1-a852-fafa7e7addbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2909, 65)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6566e31-b5a6-4740-aa33-90a9343756d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbd385c-aa22-48a1-90ec-ac11de585754",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_scaled[:, 0:5] \n",
    "y = data_scaled[:, 5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d1ab13-9b5e-4306-8001-0e1d475a51eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30396476, 0.49206349, 0.36065574, 0.515625  , 0.56666667],\n",
       "       [0.42731278, 0.48148148, 0.31147541, 0.5078125 , 0.28333333],\n",
       "       [0.51982379, 0.53968254, 0.44262295, 0.5859375 , 0.45833333],\n",
       "       ...,\n",
       "       [0.52422907, 0.51322751, 0.40983607, 0.6015625 , 0.60833333],\n",
       "       [0.50220264, 0.51322751, 0.40983607, 0.578125  , 0.43333333],\n",
       "       [0.51101322, 0.51322751, 0.39344262, 0.5546875 , 0.475     ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc53aa07-f6bc-4d60-98f6-4e16ce5cc1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aab80de-1313-4abe-a14c-162bf5568dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182bf3fa-9005-4cf0-b6cb-347cda1515ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 16:48:50.010246: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-02-16 16:48:50.010278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Kishore): /proc/driver/nvidia/version does not exist\n",
      "2023-02-16 16:48:50.010531: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c8f62c-8f88-4fa0-951d-a1fee2d6128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ab8509-6e2a-48d1-8810-2be6f160cd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 4s 9ms/step - loss: 0.0308\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0104\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0099\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0097\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0096\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0097\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0095\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0095\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0096\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0097\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0096\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0096\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0093\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0094\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0092\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0094\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0094\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0090\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0093\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0090\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0091\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0090\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0089\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0088\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0089\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0089\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0089\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0088\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0089\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0088\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0087\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0087\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0086\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0086\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0086\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0085\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0084\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0084\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0083\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0079\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0078\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0078\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0077\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0078\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0076\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0077\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0076\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0076\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0076\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0077\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0075\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0076\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0075\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0074\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0074\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0074\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0074\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0075\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0074\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0074\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0073\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0073\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0074\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0072\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0074\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0072\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.0072\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0072\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0071\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0072\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0072\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0071\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0071\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0071\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0071\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.0071\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cdc2adf30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "637a9b55-94b1-4d7b-a3f2-7b269ad32531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0069723050110042095\n",
      "Test MSE: 0.007756114471703768\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Train MSE:\", train_score)\n",
    "print(\"Test MSE:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be75da39-5856-444b-970a-6c62ea066629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.reshape((582,1))\n",
    "# y_pred.shape\n",
    "# X_test\n",
    "new_shape = (X_test.shape[0] * X_test.shape[1], X_test.shape[2],X_test.shape[1]-X_test.shape[0])\n",
    "a = np.random.rand(582)\n",
    "b = a.reshape(582, 1)\n",
    "# y_pred.reshape(529,64)\n",
    "X_2d = y_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862a73ab-4f53-4815-9e45-cfb537b6ef79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (2327,1) doesn't match the broadcast shape (2327,65)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml310/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:529\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    523\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    525\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    526\u001b[0m     X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m )\n\u001b[0;32m--> 529\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[1;32m    530\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (2327,1) doesn't match the broadcast shape (2327,65)"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "y_pred = scaler.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f89870-7cfc-41b4-8f6a-a8a691f495f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ab41c-b20b-4305-ba9b-98e8883e7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    " accuracy_score(X_2d, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1c64f-6637-4350-a323-9a25f2b5ee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
